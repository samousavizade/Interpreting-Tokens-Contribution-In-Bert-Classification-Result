{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "3OiT6jMgau3g"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install captum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0z2OJkCbLmq"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEz5cZ07bEh3",
        "outputId": "8aa570b6-dcb1-4785-d8e4-9d658e419a59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['[CLS]', 'growth', 'is', 'strong', 'and', 'we', 'have', 'plenty', 'of', 'liquidity', '[SEP]']\n",
            "[3, 64, 17, 253, 8, 13, 29, 9146, 7, 466, 4]\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
        "\n",
        "\n",
        "text = 'growth is strong and we have plenty of liquidity'\n",
        "label = 1;\n",
        "\n",
        "# Tokenize input text\n",
        "text_ids = tokenizer.encode(text, add_special_tokens=True)\n",
        "\n",
        "# Print the tokens\n",
        "print(tokenizer.convert_ids_to_tokens(text_ids))\n",
        "# Output: ['[CLS]', 'The', 'movie', 'is', 'superb', '[SEP]']\n",
        "\n",
        "# Print the ids of the tokens\n",
        "print(text_ids)\n",
        "# Output: [101, 1109, 2523, 1110, 25876, 102]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hI1f-fKcIFZ"
      },
      "source": [
        "# Fetch Embedding of Tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqehEyagcIb-",
        "outputId": "d6db4fef-5f73-4c64-86d8-b2956f7f90f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 11, 768])\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertModel\n",
        "\n",
        "# Instantiate BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone',num_labels=3)\n",
        "\n",
        "embeddings = model.bert.embeddings(torch.tensor([text_ids]))\n",
        "print(embeddings.size())\n",
        "# Output: torch.Size([1, 6, 768]), since there are 6 tokens in text_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP_ojhc6hg80"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C35kd-zQhgqF",
        "outputId": "f289e0c8-e901-458c-8925-fb3abd6484f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 'Neutral', 1: 'Positive', 2: 'Negative'}\n",
            "Positive\n"
          ]
        }
      ],
      "source": [
        "text = 'growth is strong and we have plenty of liquidity'\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(**inputs).logits\n",
        "\n",
        "predicted_class_id = logits.argmax().item()\n",
        "\n",
        "print(model.config.id2label)\n",
        "print(model.config.id2label[predicted_class_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86WZe_uRdTqF"
      },
      "source": [
        "# Define Model Input and Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "GppGG59LdQVy"
      },
      "outputs": [],
      "source": [
        "# # Define model output\n",
        "# def model_output(inputs):\n",
        "#   return model(inputs)[0]\n",
        "\n",
        "# # Define model input\n",
        "# model_input = model.bert.embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90yHmDVkdaDK"
      },
      "source": [
        "# Instantiate Integrated Gradients Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "smWwrRMudbQe"
      },
      "outputs": [],
      "source": [
        "from captum.attr import LayerIntegratedGradients\n",
        "lig = LayerIntegratedGradients(lambda inputs: model(inputs)[0], model.bert.embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qJjl986dgKt"
      },
      "source": [
        "# Construct Original and Baseline Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hu6FFtRwdgcV",
        "outputId": "1ffd89dd-b245-4e66-e02d-564726be3adf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original text: tensor([[   3,   64,   17,  253,    8,   13,   29, 9146,    7,  466,    4]])\n",
            "baseline text: tensor([[3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4]])\n"
          ]
        }
      ],
      "source": [
        "def construct_input_and_baseline(text):\n",
        "\n",
        "    max_length = 510\n",
        "    baseline_token_id = tokenizer.pad_token_id \n",
        "    sep_token_id = tokenizer.sep_token_id \n",
        "    cls_token_id = tokenizer.cls_token_id \n",
        "\n",
        "    text_ids = tokenizer.encode(text, max_length=max_length, truncation=True, add_special_tokens=False)\n",
        "   \n",
        "    input_ids = [cls_token_id] + text_ids + [sep_token_id]\n",
        "    token_list = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "  \n",
        "\n",
        "    baseline_input_ids = [cls_token_id] + [baseline_token_id] * len(text_ids) + [sep_token_id]\n",
        "    return torch.tensor([input_ids], device='cpu'), torch.tensor([baseline_input_ids], device='cpu'), token_list\n",
        "\n",
        "# text = 'This movie is superb'\n",
        "input_ids, baseline_input_ids, all_tokens = construct_input_and_baseline(text)\n",
        "\n",
        "print(f'original text: {input_ids}')\n",
        "print(f'baseline text: {baseline_input_ids}')\n",
        "\n",
        "# Output: original text: tensor([[  101,  1109,  2523,  1110, 25876,   102]])\n",
        "# Output: baseline text: tensor([[101,   0,   0,   0,   0, 102]])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h_EH7WRdrGR"
      },
      "source": [
        "# Compute Attributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH01AZlCdrb2",
        "outputId": "9fbb65b4-2a2d-4acb-ce2f-226a18bfabff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 11, 768])\n"
          ]
        }
      ],
      "source": [
        "attributions, delta = lig.attribute(\n",
        "    inputs=input_ids,\n",
        "    baselines=baseline_input_ids,\n",
        "    target=label,\n",
        "    return_convergence_delta=True\n",
        ")\n",
        "print(attributions.size())\n",
        "# Output: torch.Size([1, 6, 768])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok0bMG_vrW5b"
      },
      "source": [
        "# Compute Attribution for Each Token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVyVPizhrXO1",
        "outputId": "e190eb9f-a3a6-4423-d008-4a2e8b174c4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([11])\n"
          ]
        }
      ],
      "source": [
        "def summarize_attributions(attributions):\n",
        "\n",
        "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
        "    attributions = attributions / torch.norm(attributions)\n",
        "    \n",
        "    return attributions\n",
        "\n",
        "attributions_sum = summarize_attributions(attributions)\n",
        "print(attributions_sum.size())\n",
        "# Output: torch.Size([6])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O_OveCcrzhp"
      },
      "source": [
        "# Encapsulate All the Steps Above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "bBi2eoOIr0az"
      },
      "outputs": [],
      "source": [
        "def interpret_text(text, true_class):\n",
        "\n",
        "    input_ids, baseline_input_ids, all_tokens = construct_input_and_baseline(text)\n",
        "    attributions, delta = lig.attribute(inputs= input_ids,\n",
        "                                    baselines= baseline_input_ids,\n",
        "                                    target=true_class,\n",
        "                                    return_convergence_delta=True\n",
        "                                    )\n",
        "    attributions_sum = summarize_attributions(attributions)\n",
        "\n",
        "    score_vis = viz.VisualizationDataRecord(\n",
        "                        word_attributions = attributions_sum,\n",
        "                        pred_prob = torch.max(model(input_ids)[0]),\n",
        "                        pred_class = torch.argmax(model(input_ids)[0]).numpy(),\n",
        "                        true_class = true_class,\n",
        "                        attr_class = text,\n",
        "                        attr_score = attributions_sum.sum(),       \n",
        "                        raw_input_ids = all_tokens,\n",
        "                        convergence_score = delta)\n",
        "\n",
        "    viz.visualize_text([score_vis])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "dvc9Dw68siic",
        "outputId": "a3285a63-2c3e-47a1-c3da-53c443a25a8b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>1 (2.99)</b></text></td><td><text style=\"padding-right:2em\"><b>Stocks rallied and the British pound gained.</b></text></td><td><text style=\"padding-right:2em\"><b>0.52</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> stocks                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ral                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##lied                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> british                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pound                    </font></mark><mark style=\"background-color: hsl(120, 75%, 52%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> gained                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>1 (10.98)</b></text></td><td><text style=\"padding-right:2em\"><b>growth is strong and we have plenty of liquidity</b></text></td><td><text style=\"padding-right:2em\"><b>0.85</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> growth                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 54%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> strong                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> we                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> have                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> plenty                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> liquidity                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "text = \"Stocks rallied and the British pound gained.\"\n",
        "true_class = model.config.label2id[\"Positive\"]\n",
        "\n",
        "interpret_text(text, true_class)\n",
        "\n",
        "\n",
        "text = 'growth is strong and we have plenty of liquidity'\n",
        "true_class = model.config.label2id[\"Positive\"];\n",
        "interpret_text(text, true_class)\n",
        "  "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
